{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d690f0fb",
   "metadata": {},
   "source": [
    "# Modelado de Inundaciones con Machine Learning\n",
    "\n",
    "Este notebook desarrolla un modelo de clasificación para predecir eventos de inundación utilizando datos climáticos procesados en la fase de limpieza.  \n",
    "Incluye los siguientes pasos:\n",
    "\n",
    "- Carga del dataset limpio  \n",
    "- Creación de la variable objetivo para identificar inundaciones  \n",
    "- Selección de variables relevantes  \n",
    "- División del dataset en entrenamiento y prueba  \n",
    "- Entrenamiento de un modelo de Machine Learning  \n",
    "- Evaluación mediante métricas de desempeño  \n",
    "- Visualización de importancia de variables  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paso 1: Cargamos el dataset limpio\n",
    "BASE_DIR = Path(\"..\").resolve()     \n",
    "\n",
    "# Carpeta donde se guardan los datasets limpios\n",
    "data_path = BASE_DIR / \"DataClean\" / \"master\"\n",
    "\n",
    "# Cargar el dataset \"wide\" (TEMP, HUMEDAD, LLUVIA, VIENTO)\n",
    "df = pd.read_parquet(data_path / \"master_dataset_final_wide.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "added616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 2 Creamos una variable objetivo\n",
    "\n",
    "df[\"flood_label\"] = (df[\"LLUVIA\"] > 30).astype(int)\n",
    "df[\"flood_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81332c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paso 3 Separamos caracteristicsas y etiquetas\n",
    "X = df[[\"TEMP\", \"HUMEDAD\", \"LLUVIA\", \"VIENTO\"]] \n",
    "y = df[\"flood_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 4 Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca75540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso 5 el entrenamiendo del modelo\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a6729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 6 evalucion\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0703ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 7, ver las importancias de variables\n",
    "importances = model.feature_importances_\n",
    "plt.bar(X.columns, importances)\n",
    "plt.title(\"Importancia de Variables\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
